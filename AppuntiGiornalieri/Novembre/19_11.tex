\documentclass[../../FisicaTeorica.tex]{subfiles}
\begin{document}

\begin{comment}
Partendo da due particelle con funzioni d'onda $\psi_1(\vec{x}^{(1)}) \in L^2(\bb{R}^3,d^3x)$  e $\psi(\vec{x}^{(2)})\in L^2(\bb{R}^3, d^3x)$, il sistema composto da entrambe avrà una funzione d'onda $\psi(\vec{x}^{(1)}, \vec{x}^{(2)}) \in L^2(\bb{R}^6, d^3x^{(1)},d^3x^{(2)})$. Qual è la relazione tra quest'ultima $\psi$ \q{composta} e le due \q{singole}?\\
\end{comment}
Prima di farlo, è necessario sviluppare una nozione di algebra lineare.\\
\begin{dfn}
Dati \marginpar{Prodotto tensore}\index{Prodotto tensore}due spazi di Hilbert $\hs_1$, $\hs_2$, siano $\varphi_1 \in \hs_1$, $\varphi_2\in \hs_2'$ funzionali lineari\footnote{Dato che sussiste un isomorfismo tra $\hs$ e il suo duale $\hs'$, si ha che agli effetti $\hs=\hs'$, e quindi non è indispensabile indicare l'apice.}, e si denoti con $\varphi_1 \otimes \varphi_2$ la forma bilineare sul prodotto cartesiano $\hs_1 \times \hs_2$ definita da:
\begin{equation}
\varphi_1 \otimes \varphi_2 (\underbrace{\{\psi_1, \psi_2\}}_{\hs_1 \times \hs_2})=(\varphi_1, \psi_1)_{\hs_1} (\varphi_2, \psi_2)_{\hs_2}
\label{eqn:forma-bilineare}
\end{equation}
In altre parole, \textit{combiniamo} due funzionali lineari definiti su due spazi diversi $\hs_1$ e $\hs_2$ per definire un nuovo funzionale, che stavolta agisce su \textit{coppie} di vettori del tipo $\{\psi_1 \in \hs_1, \psi_2 \in \hs_2\}$, applicando su ciascun membro il \textit{rispettivo funzionale} (ossia $\varphi_1$ su $\psi_1$, e $\varphi_2$ su $\psi_2$) per poi fare il prodotto dei risultati. Dato che l'azione su entrambi gli elementi della coppia è lineare, tale nuovo funzionale - che chiamiamo $\varphi_1 \otimes \varphi_2$, si dice \textbf{bilineare}. Valgono cioè:
\begin{align*}
\varphi_1 \otimes \varphi_2(\{a\psi_a + b\psi_b,\psi_2\})&=a\varphi_1\otimes\varphi_2(\{\psi_a,\psi_2\}) + b \varphi_1 \otimes \varphi_2(\{\psi_b,\psi_2\})\\
\varphi_1\otimes \varphi_2(\{\psi_1, a\psi_a+b\psi_b\})&=a\,\varphi_1\otimes\varphi_2(\{\psi_1,\psi_a\})+b\,\varphi_1\otimes\varphi_2(\{\psi_1,\psi_b\})
\end{align*}
e la relazione analoga in cui si scambiano i due termini della coppia.\\

Vorremmo ora che lo spazio di questi nuovi funzionali sia di Hilbert. Costruiamolo per passi.\\
Denotiamo con $\mathcal{E}$ l'insieme delle combinazioni lineari \textit{finite} di forme bilineari definite come sopra. In tal modo su $\mathcal{E}$ è sempre definita la somma di funzionali e il loro prodotto per uno scalare, e quindi $\mathcal{E}$ è (ovviamente) uno spazio vettoriale, la cui base sarà data dai funzionali ottenuti \textit{moltiplicando tensorialmente} i funzionali delle basi di $\hs_1$ e $\hs_2$. Esplicitamente, se $\{e_i\}$ è una base di $\hs_1'$ e $\{v_j\}$ di $\hs_2'$, una base di $\mathcal{E}$ è data da $\{e_i \otimes v_j\} \> \forall i,j$.\\
Rendiamo ora $\mathcal{E}$ pre-hilbertiano definendo su di esso un \textit{prodotto scalare} come:
\begin{equation}
(\varphi_1 \otimes \varphi_2, \chi_1 \otimes \chi_2)\equiv (\varphi_1, \chi_1)_{\hs_1}(\varphi_2,\chi_2)_{\hs_2}
\label{eqn:prod_scalare}
\end{equation}
In effetti basta definirlo sulla base di $\mathcal{E}$ e poi estenderlo \textit{per linearità}: precisamente, dato che ogni \textit{vettore} di $\mathcal{E}$ è combinazione lineare di elementi della base, il prodotto scalare tra due generici vettori può essere definito, grazie alla sua linearità, come combinazione dei prodotti scalari degli elementi di base.\\
\textbf{Nota}: qui stiamo definendo un prodotto scalare \textit{tra forme bilineari} (che sono i \q{vettori} di $\mathcal{E}$), e quindi tale formula non va confusa con la definizione data in (\ref{eqn:forma-bilineare}).\\

Il prodotto scalare che abbiamo introdotto definisce una \textit{norma}, e quindi una nozione di \textit{convergenza}. Possiamo allora \textit{completare\footnote{Possiamo farlo per il \textit{teorema del completamento}, dato che $\mathcal{E}$ è unitario. CFR pag. 10 di \cite{spazi_hilbert}}} $\mathcal{E}$ aggiungendo ad esso anche i vettori $\psi$ che si ottengono come combinazioni lineari \textit{infinite}:
\[
\psi=\sum_{nm} c_{nm} \psi_n^{(1)}\otimes\psi_m^{(2)}
\]
se, ovviamente, tali somme hanno senso, ossia se \textit{convergono} secondo la norma indotta dal prodotto scalare in (\ref{eqn:prod_scalare}).\\

Una volta fatto questo, lo spazio $\mathcal{E}$ è \textbf{completo}, e quindi di Hilbert, e lo denotiamo con $\hs_1 \otimes \hs_2$. Tale spazio si dice \textbf{prodotto tensore} di $\hs_1$ e $\hs_2$.
\end{dfn}
Possiamo rendere questa definizione \q{più semplice} concretizzandola utilizzando le basi degli spazi di Hilbert.
\begin{thm}
Se $\{e_n^{(1)}\}_{n\in N}$ è\marginpar{Base dello spazio prodotto} una base per $\hs_1$, e $\{e_m^{(2)}\}_{m\in M}$ per $\hs_2$, allora $\{e_n^{(1)}\otimes e_m^{(2)}\}_{n\in N, m\in M}$ è una base per $\hs_1 \otimes \hs_2$.\\
Valgono allora i seguenti \textbf{isomorfismi} (che esaminiamo senza dimostrare):
\begin{itemize}
\item 
$\displaystyle
L^2(\bb{R}^n, d^nx) \otimes L^2(\bb{R}^m,d^my) \cong L^2(\bb{R}^{n+m}, d^n x\,d^m y)
$\\
Cioè, prendendo un $\phi_n(x)\in L^2(\bb{R}^n,d^n x)$ e un $\psi_m(y) \in L^2(\bb{R}^n, d^n x)$, costruiamo un isomorfismo tra gli spazi sopra considerati tramite: 
\begin{align}
    U(x,y) &\in L^2(\bb{R}^{n+m}, d^nx\, d^my)\\
    U: &\phi_n(x) \otimes \psi_m(y) \mapsto \phi_n(x)\psi_m(y)
\end{align}
dove $x$ è un vettore $n$-dimensionale e $y$ un vettore $m$-dimensionale, e $\phi_n$, $\psi_m$ sono funzioni (modulo quadro integrabili) di questi vettori, estendendo poi per linearità a combinazioni lineari finite e poi per continuità agli interi spazi.\\
Alternativamente, per definire $U$ basta specificare cosa fa se applicata ai vettori $\{v_i\}$ e $\{w_i\}$ delle basi di $L^2(\bb{R}^n)$ e $L^2(\bb{R}^m)$, e poi \textbf{estendere per linearità e continuità}.\\
Nello specifico, fissati i valori di $U(v_i \otimes w_j)$, $U$ è una funzione di vettori $a \in \bb{R}^{n+m}$. Spezzando $a = (a', a'')$ (prime $n$ componenti e restanti $m$), dato che $a'$ e $a''$ sono combinazioni lineari delle basi:
\[
a' = \sum_i c_i v_i; \quad a'' = \sum_j d_j w_j
\]
Possiamo scrivere:
\[
U(a)=U((a',a''))= U\left(\sum_{i} c_i v_i, \sum_j d_j w_j\right)= \sum_{ij} c_i d_j U(v_i \otimes w_j)
\]
che ha un valore definito dato che abbiamo fissato gli $U(v_i \otimes w_j)$.
\item Un altro isomorfismo interessante è:
\begin{align}
L^2(\bb{R}^n, d^nx) \otimes \bb{C}^l \cong \underbrace{L^2(\bb{R}^n, d^n x) \oplus \dots \oplus L^2(\bb{R}^n, d^nx)}_{l-volte}
\label{eqn:isomorfismo-prodotto-tensore}
\end{align}
\begin{expl}
In generale, se $V$ e $W$ sono spazi vettoriali, $V^* \otimes W$ contiene le funzioni lineari che vanno da $V\to W$. Più precisamente esiste un isomorfismo\footnote{Una dimostrazione di ciò è data a pag. 5 della Lezione 9 disponibile sul Moodle del corso di Geometria Differenziale tenuto dal prof. Bottacin.} $F$:
\begin{align*}
F: V^* \otimes W & \to \op{Hom}(V,W)\\
F(\underbrace{\varphi \otimes w}_{\in V^* \otimes\ W})(v) &= \underbrace{\varphi(v)w}_{\in\ W}
\end{align*}
dove $\varphi \in V^*$ è un funzionale, e $w\in W$ è un vettore.\\
Finora abbiamo parlato però di prodotto tensore tra funzionali, mentre nell'espressione soprastante $w$ è chiaramente un vettore. Cosa significa, perciò, $\varphi\otimes w$?

L'idea sta nel notare che se lo spazio duale $W^*$ è quello delle funzioni lineari $W\to \bb{R}$ (indicato come $\op{Hom}(W,\bb{R})$), il duale del duale $W^{**}$ contiene le funzioni $W^* \to \bb{R}$, e per uno spazio finito-dimensionale coincide (cioè, è canonicamente isomorfo) con $W$ stesso. Possiamo cioè vedere i vettori di $W$ come \q{funzioni di funzionali}, ossia un \textit{vettore} di $W$ applicato ad un funzionale di $W^*$ produce un numero.\\
Preso allora $\varphi \in V^*$, e $w \in W$, il loro prodotto tensore sarà una funzione bilineare che si applica contemporaneamente agli elementi a cui si applicherebbero singolaremente $\varphi$ e $w$, ossia, rispettivamente, vettori $v \in V$ e funzionali $\phi \in W^*$: $(\varphi \otimes w):V\times W^* \to\bb{R}$. Esplicitamente sarà proprio il prodotto delle singole \q{applicazioni}:
\[
(\varphi \otimes w)(v,\phi) =\varphi(v) \phi(w)
\]
\end{expl}
Si ha quindi che $L^2(\bb{R}^n) \otimes \bb{C}^l$ contiene le funzioni (modulo quadro integrabili) da $\bb{R}^n \to \bb{C}^l$. Ma tali funzioni non sono altro che un \textit{vettore} di \q{normali} funzioni $L^2(\bb{R}^n)$, che possiamo scrivere come:
\[
\begin{pmatrix}
\psi_1(x)\\
\psi_2(x)\\
\vdots\\
\psi_l(x)
\end{pmatrix} \quad \psi_i(x) \in L^2(\bb{R}^n, d^n x)\quad i=1,\dots,l
\]
\item Ricordando che $\bb{R}^3 \cong \bb{R}_+ \times S^2$ (cioè possiamo rappresentare un punto dello spazio in coordinate sferiche, scrivendo $d^3 x = r^2\,dr \cdot d\Omega$, con $d\Omega = \sin\theta\,d\theta\,d\varphi$), nella notazione dei prodotti tensori avremo che:
\[
L^2(\bb{R}^3, d^3x)\cong L^2(\bb{R}_+, r^2\,dr)\otimes L^2(S^2, d\Omega)
\]
\end{itemize}
\end{thm}



Operatori\marginpar{Prodotto tensore di operatori} in $\hs_1 \otimes \hs_2$ della forma $A^{(1)}\otimes A^{(2)}$ con $A^{(1)}$ che agisce su $\hs_1$ e $A^{(2)}$ su $\hs_2$ sono definiti per estensione (lineare e continua) da:
\begin{equation}
(A^{(1)}\otimes A^{(2)})(\varphi^{(1)}\otimes \varphi^{(2)}
)=A^{(1)}\varphi^{(1)} \otimes A^{(2)}\varphi^{(2)}
\label{eqn:prod_tensore_operatori}
\end{equation}
\textbf{Attenzione}: tuttavia gli operatori in $\hs_1 \otimes \hs_2$ sono in generale della forma di combinazioni lineari:
\[
\sum_{m,n} c_{mn} A_m^{(1)}\otimes A^{(2)}_n
\]
(dove la somma è potenzialmente infinita). Perciò non tutti gli operatori sullo \q{spazio grande} sono ottenibili come prodotti tensori degli operatori sugli \q{spazi piccoli} che lo compongono.
\begin{expl}
Ragionando in dimensione finita, un esempio \textit{banale} di ciò è dato qui di seguito.\\
Siano $\vec{v},\vec{w}\in \bb{R}^2$, e $A$ una forma bilineare, definita come:
\[
\vec{v}=\begin{pmatrix}x_1\\ x_2\end{pmatrix} \quad \vec{w}=\begin{pmatrix} y_1 \\ y_2 \end{pmatrix}\quad A(\vec{v},\vec{w})=3x_1\,y_1
\]
In questo caso è facile scomporre $A$ nel prodotto di due funzioni che agiscono rispettivamente su $\vec{v}$ e su $\vec{w}$:
\[
A(\vec{v},\vec{w})=f(\vec{v}) g(\vec{w}) \quad f(\vec{v}) =3x_1 \quad g(\vec{w})=y_1
\]
E in questo senso si potrebbe scrivere:
\[
f,g:\bb{R}^2\to\bb{R},\quad 
A = f \otimes g: \bb{R}^2\times\bb{R}^2\to\bb{R},\quad A\in \bb{R}'^2 \otimes \bb{R}'^{2}
\]
Ma una \textit{scomposizione} analoga non si può più fare per la forma bilineare $B$:
\[
B(\vec{v},\vec{w})=3x_1 y_1 +x_2 y_2
\]
Notiamo però che i singoli addendi nella definizione di $B$ sono scomponibili come prodotti tensori di opportune funzioni. In questo senso $B$ è una \textit{combinazione lineare} di prodotti tensori.\\
Se matematicamente ciò è ovvio, vedremo che le conseguenze fisiche sono radicali. Uno stato nello spazio \textit{prodotto-tensore} $\hs_1\otimes \hs_2$ non è detto che sia il prodotto tensore di uno stato in $\hs_1$ e uno stato in $\hs_2$: potrebbe benissimo essere una combinazione lineare di prodotti del genere. %[TO DO] Completare con il perché è così sconvolgente 
\end{expl}

Un caso particolare di operatori definiti sullo spazio prodotto tensore è dato da $\underbrace{A^{(1)}\otimes \bb{I}^{(2)}}_{a}$ e $\underbrace{\bb{I}^{(1)}\otimes A^{(2)}}_{b}$ (per cui ciascuno dei due \q{agisce} solo sulla rispettiva parte dello spazio, e agisce come identità su tutto il resto).\\
Essi commutano tra loro, infatti:
\begin{align*}
&\overbrace{(A^{(1)}\otimes \bb{I}^{(2)})}^{a}\overbrace{(\hlc{Yellow}{\bb{I}^{(1)}}\otimes \hlc{SkyBlue}{A^{(2)}})}^{b}(\hlc{Yellow}{\varphi_1^{(1)}}\otimes \hlc{SkyBlue}{\varphi^{(2)}})=(A^{(1)}\otimes \bb{I}^{(2)})(\hlc{Yellow}{\varphi^{(1)}}\otimes \hlc{SkyBlue}{A^{(2)}\varphi^{(2)}})=\\
&=(A^{(1)}\varphi^{(1)}\otimes A^{(2)}\varphi^{(2)})=(\bb{I}^{(1)}\otimes A^{(2)})(A^{(1)}\varphi^{(1)}\otimes \varphi^{(2)})=\\
&=\underbrace{(\bb{I}^{(1)}\otimes A^{(2)})}_{b}\underbrace{(A^{(1)}\otimes \bb{I}^{(2)})}_{a}(\varphi^{(1)}\otimes \varphi^{(2)})
\end{align*}

Partendo allora da:
\[
\underbrace{L^2(\bb{R}^3, d^3x)}_{\ni \psi(\vec{x})} \otimes\underbrace{ L^2(\bb{R}^3, d^3 y) }_{\ni\psi(\vec{y})}\cong \underbrace{L^2(\bb{R}^6, d^3x\,d^3y)}_{\ni \psi(\vec{x},\vec{y})}
\]
Abbiamo un'idea per estendere l'equazione di Schr\"odinger al caso dei sistemi composti. Enunciamo quindi l'assioma:
\begin{axi}
Quando un\marginpar{Assioma dei sistemi composti}\index{Assioma!dei sistemi composti} sistema quantistico consiste in $N$ sistemi \textbf{distinguibili} con spazi di Hilbert $\hs_i$, $i=1,\dots, N$, il sistema totale ha come spazio di Hilbert il prodotto tensore degli spazi di Hilbert dei costituenti, cioè:
\[
\hs_1 \otimes \hs_2 \otimes \cdots \otimes \hs_N = \bigotimes_{i=1}^N \hs_i
\]
e le osservabili $A^{(i)}$ del sottosistema $i$-esimo nel sistema totale sono date da:
\[
\bb{I}^{(1)}\otimes \cdots \otimes \bb{I}^{(i-1)}\otimes A^{(i)}\otimes \bb{I}^{(i+1)}\otimes \cdots \otimes \bb{I}^{(N)}
\]
In notazione di\ Dirac, se $\ket{\psi^{(1)}}\in \hs_1$ e $\ket{\phi^{(2)}}\in \hs_2$ lo stato prodotto tensore è denotato \q{implicitamente} con:
\[
\ket{\psi^{(1)}}\ket{\phi^{(2)}} \equiv \ket{\psi^{(1)}}\otimes \ket{\phi^{(2)}}
\]
\end{axi}
Poiché, come abbiamo visto, le osservabili che agiscono su ciascun sistema commutano con le osservabili che agiscono su tutti gli altri sottosistemi, se $\mathcal{C}_i$ è un ICOC per il sistema $S_i$, allora un ICOC per il sistema totale $S=\bigcup_{n=1}^N S_i$ è l'insieme degli ICOC dei sottosistemi $\{\mathcal{C}_i\}_{i=1,\dots,N}$.\\

Fermiamoci un attimo a riflettere su tali risultati. Se utilizziamo l'interpretazione ondulatoria, per cui le particelle sono rappresentate da \textit{onde di probabilità}, quello che abbiamo ottenuto è sconvolgente. Ci aspettiamo che la funzione d'onda del sistema composto \textit{appartenga ancora allo spazio tridimensionale}. Abbiamo invece trovato che, per $2$ particelle in 3D, la $\psi(\vec{x},\vec{y})$ è definita sullo spazio dei prodotti cartesiani, che è a $6$ dimensioni!\\
La ragione di ciò è che abbiamo descritto lo spazio degli stati puri come \textbf{lineare}, e perciò bisogna poter sommare i prodotti delle funzioni dei due sottosistemi, e quindi lo spazio deve avere per forza una dimensione più grande.\\
Per esempio, consideriamo una misura di \textit{polarizzazione} dei fotoni, che in 2D sono scritte come combinazione lineare di vettori $\ket{x}$ e $\ket{y}$.\\
Facendo una misura (ideale di prima specie) di $x$ sul primo fotone e di $x$ sul secondo, lo stato finale è indicato da $\ket{x^{(1)}}\ket{x^{(2)}}$. Analogamente per $y$: $\ket{y^{(1)}}\ket{y^{(2)}}$. Ma lo stato più generale non sarà uno di questi, ma una combinazione lineare del tipo:
\[
\ket{x^{(1)}}\ket{x^{(2)}} + \ket{y^{(1)}}\ket{y^{(2)}}
\]
che non si può scrivere come prodotto degli stati dei due sistemi \q{separati} (è una combinazione lineare di tali prodotti).\\

\begin{oss} \textbf{Importante!}\\
Per la \textbf{linearità} degli spazi vettoriali, nel nostro caso di Hilbert, e per la definizione di \textbf{prodotto tensore}, esistono stati del sistema composto che \textbf{non sono scrivibili} come prodotto tensore di stati dei sottosistemi (basta che siano una combinazione lineare di prodotti di stati singoli \q{non separabile} in un unico prodotto).\\
Stati di questo tipo si dicono \textbf{entangled} (=\textit{allacciati}) Essi descrivono una situazione in cui le proprietà dei sottosistemi non sono indipendenti, forzando una \q{realtà allacciata} dei sottosistemi.\\
Questo è un fenomeno puramente quantistico, perché è necessaria la natura vettoriale per definire $\otimes$! Ciò è alla base di alcuni dei fenomeni più sconcertanti e delle tecnologie quantistiche, come il paradosso EPR, il teletrasporto quantistico, computer quantistico, crittografia quantistica.
\end{oss}

\begin{oss}
Riprendiamo lo stato entangled visto prima:
\[
\ket{\psi}\sim
\ket{x^{(1)}}\ket{x^{(2)}} + \ket{y^{(1)}}\ket{y^{(2)}}
\]
Normalizziamolo e riscriviamolo in una notazione \q{più suggestiva}:
\begin{align*}
\ket{\psi}= \frac{1}{\sqrt{2}}(
\ket{\rightarrow_1}\ket{\rightarrow_2}+\ket{\uparrow_1}\ket{\uparrow_2})
\end{align*}
Cosa succede se facciamo una misura su di esso? Proviamo, per esempio, a misurare la polarizzazione, lungo $\rightarrow$, del fotone $1$. Poiché lo stato del fotone $1$ è una combinazione di $\ket{\rightarrow}$ e $\ket{\uparrow}$ \textit{in parti uguali}, la probabilità di trovare il fotone orientato lungo $\rightarrow$ o meno è del $50\%$:
\begin{align*}
p(\rightarrow_1)= \left|\braket{\rightarrow|\frac{1}{\sqrt{2}}(\ket{\rightarrow_1}+\ket{\uparrow_1})}\right|^2 = \frac{1}{2}
\end{align*}
A seguito della misura (ideale di prima specie), lo stato \textit{collasserà} nell'autospazio \textit{compatibile} con l'autovalore misurato. Per esempio, se rileviamo il fotone $1$ con polarizzazione $\rightarrow$ (ossia se \textit{attraversa} un filtro orientato lungo quell'asse), il nuovo stato del sistema sarà ottenuto applicando il \textit{proiettore} $\ket{\rightarrow_1}\bra{\rightarrow_1} \otimes \bb{I}$ a $\ket{\psi}$, da cui si ottiene:
\begin{align*}
\ket{\psi_f} = (\hlc{Yellow}{\ket{\rightarrow_1}\bra{\rightarrow_1}}  \otimes \hlc{SkyBlue}{\bb{I}}) \frac{1}{\sqrt{2}}(\hlc{Yellow}{
\ket{\rightarrow_1}}\hlc{SkyBlue}{\ket{\rightarrow_2}}+\hlc{Yellow}{\ket{\uparrow_1}}\hlc{SkyBlue}{\ket{\uparrow_2}}) = \ket{\rightarrow_1}\ket{\rightarrow_2}
\end{align*}
dove ciascuna parte del proiettore agisce sui termini evidenziati con lo stesso colore.\\
Notiamo ora che se misuriamo la polarizzazione del fotone $2$ nel nuovo stato $\ket{\psi_f}$ otterremo \textit{sempre} il risultato $\rightarrow$, cosa che non era vera per $\ket{\psi}$ iniziale. Ciò significa che la misura di polarizzazione del fotone $1$ ci ha dato informazione anche sulla polarizzazione del fotone $2$.\\

Ciò inizialmente potrebbe non sembrare strano, dato che \q{più misure in una volta sola} si possono fare anche in fisica classica. Per esempio, si considerino due sferette di masse e velocità iniziali conosciute, che urtano elasticamente ad un certo istante $t$. A $t^+$ basta misurare la velocità di una sola delle due per sapere, \textit{per conservazione del momento}, la velocità dell'altra.\\

In \MQ, tuttavia, la faccenda è complicata dal fatto che, a differenza del caso classico, le osservabili non sono \textit{sempre definite}: nello stato $\ket{\psi}$, il primo fotone \textit{non} ha una polarizzazione \q{predeterminata} prima che essa venga misurata. Perciò la misura sul primo fotone ritorna un valore \textit{scelto a caso}, e quella sul secondo avrà lo \textit{stesso valore della prima}. Tuttavia i due fotoni del sistema possono essere separati a grande distanze, e le due misure fatte contemporaneamente, in modo che \textit{non vi sia possibilità} che un qualsiasi segnale possa trasmettersi dalla prima alla seconda, se non a velocità superiori della luce, il che è paradossale.\\
Sarebbe come lanciare una moneta e sapere \textit{con certezza} che un'altra moneta, dall'altro capo del mondo, è atterrata con la stessa faccia. Ciò avrebbe senso, classicamente, solo se le due monete fossero \textit{truccate}, ossia avessero una sola faccia (uguale in entrambe), e il lancio della prima moneta sia dovuto all'ignoranza dello sperimentatore che non sa di avere a che fare con una moneta del genere.\\
Una teoria del genere è detta \textit{a variabili nascoste}. Come vedremo in un prossimo capitolo, la supposizione che il risultato di una misura sia in un qualche modo determinato da \q{variabili inaccessibili} che si comportino rispettando la località è incompatibile con le previsioni matematiche, e sperimentalmente verificabili, della \MQ.
\end{oss}

\end{document}

